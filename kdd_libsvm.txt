bin/spark-shell --jars "/tmp/kdd/spark-liblinear-1.95.jar"



import tw.edu.ntu.csie.liblinear._

val data = Utils.loadLibSVMData(sc, "hdfs://master01:9000/tmp/part-00002")

val model = SparkLiblinear.train(data, "-s 0 -c 1.0")

val labelAndPreds = data.map { point =>

  val prediction = model.predict(point)
 
  //target    prob.y       
  println(point.y)
  (point.y, prediction)
    
}


val accuracy = labelAndPreds.filter(r => r._1 == r._2).count.toDouble / data.count

val tp = labelAndPreds.filter{r => (r._2!=0.0) && (r._1 == r._2)}.count.toDouble
val fn = labelAndPreds.filter{r => (r._2!=0.0) && (r._1 != r._2)}.count.toDouble
val tn = labelAndPreds.filter{r => (r._2==0.0) && (r._1 == r._2)}.count.toDouble
val fn = labelAndPreds.filter{r => (r._2==0.0) && (r._1 != r._2)}.count.toDouble

val acc = (tp+tn)/(tp+fp+tn+fn)
val pos_prec = tp / (tp+fp)
val pos_rec  = tp / (tp+fn)
val neg_prec = tn / (tn+fn)
val neg_rec  = tn / (tn+fp)

println("Accuracy  = " + accuracy + "\nPrecision = " + pos_prec + "\nRecall    = pos_rec")